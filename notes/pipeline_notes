Dev Study pipeline

===================================================================
=======================OLD SCRIPTS FROM TACC=======================
===================================================================

Setup environment
Input: system, x11, libmng modules; dev_study python environment, TODO_PATH, SERVER_SCRIPTS, DATA_LOC, R_LIB paths
Script: DevStudy_ServerScripts/setup/dev_study_env.sh
Output: NA

Make BIDS compatible directories for all subjects (TACC)
Input: sub_dirname_list.txt
Script: make_bids_subject_dirs.py
Output: dev_study/data/sub-*

Make BIDS compatible content directories for all subjects
Input: sub_dirname_list.txt
Script: make_bids_content_dirs.py
Output: dev_study/data/sub-*/anat, dev_study/data/sub-*/func, dev_study/data/sub-*/fmap, dev_study/data/sub-*/behav

Unzip DICOMs (TACC)
Input: dev_study/01_DICOM_zipfiles_from_XNAT/*.zip
Script: unzip_dicom_dirs.py
Output: dev_study/02_DICOM_data_after_unzipping/*

Make commands for DICOM to NIFTO conversion (TACC)
Input: dev_study/02_DICOM_data_after_unzipping/*
Script: python make_commands_for_nifti_conversion.py > exec_convert_dicoms_to_niftis.sh
Output: dev_study/03_DICOM_to_NIFTI_conversions/* (shell directories), exec_convert_dicoms_to_niftis.sh

Convert DICOMs to NIFTIs (TACC)
Input: dev_study/02_DICOM_data_after_unzipping/* (unzipped dicom's)
Script: launch -s /corral-repl/utexas/poldracklab/users/zenkavi/dev_study/scripts/exec_convert_dicoms_to_niftis.sh -j dcm2nii -q normal -m zenkavi@stanford.edu
Output: dev_study/03_DICOM_to_NIFTI_conversions/* (nifti files)

Make commands for scripts to create behavioral events files (TACC)
Input: dev_study/todo/behav_data_tb_organized/machine_game
Script: python make_commands_for_run_events.py > exec_make_run_events.sh
Output: exec_make_run_events.sh

Make events files for functional scans
Input: dev_study/todo/behav_data_tb_organized/machine_game, make_run_events.py
Script: launch -s /corral-repl/utexas/poldracklab/users/zenkavi/dev_study/scripts/exec_make_run_events.sh -j runevs
Output: dev_study/data/sub-*/fun/sub-*/*_events.tsv

Make commands to convert BART files to tsv's
Input: setup/dev_study_env.sh
Script: python make_commands_for_bart_conversion.py > task_list_bart_mat_to_tsv.sh
Output: task_list_bart_mat_to_tsv.sh

Convert BART mat files to tsv's
Input: dev_study/todo/behav_data_tb_organized/bart/*.mat, convertBARTmat2tsv.R, 'R.matlab', 'RJSONIO', 'plyr', task_list_bart_mat_to_tsv.sh
Script: sbatch convert_bart_to_tsv.batch
Output: dev_study/data/sub-*/behav/*.tsv, dev_study/data/sub-*/behav/*.json

Make commands to move converted NIFTIs into BIDS directories
Input: dev_study/DevStudy_TaccScripts/sub_dirname_match_list.tsv
Script: python make_commands_for_move_niftis.py > exec_move_niftis_to_bids.sh
Output: exec_move_niftis_to_bids.sh

Move NIFTIs to BIDS directories
Input: dev_study/03_DICOM_to_NIFTI_conversion/*, dev_study/DevStudy_TaccScripts/move_niftis_to_bids.py
Script: launch -s /corral-repl/utexas/poldracklab/users/zenkavi/dev_study/scripts/exec_move_niftis_to_bids.sh -j movenii
Output: dev_study/data/sub-*/anat/*, dev_study/data/sub-*/func/*, dev_study/data/sub-*/fmap/*

Manual corrections for BIDSification
Script: manual_corrections.sh

===================================================================
=====================NEW SCRIPTS FROM SHERLOCK=====================
===================================================================

==============================fit_rl===============================

Input:
Script: make_commands_for_rl_fits.py
Output:

Input: $SERVER_SCRIPTS/fit_rl/fit_rl.batch, $SERVER_SCRIPTS/fit_rl/fit_rl.py, $SERVER_SCRIPTS/fit_rl/.rl_task_lists, $SERVER_SCRIPTS/.err, $SERVER_SCRIPTS/.out
Script: run_fit_rl.sh
Output: $SERVER_SCRIPTS/fit_rl/.fits/LearningParams_Fit_*_Fix_*_{sub_num}.csv

Input:
Script: concat_rl_output.py -r fits
Output: $SERVER_SCRIPTS/fit_rl/.preds/LearningParams_*_All.csv

rsync -avzh --include='*_All.csv' --include='*/' --exclude='*' zenkavi@dtn.sherlock.stanford.edu:/oak/stanford/groups/russpold/users/zenkavi/DevStudy_ServerScripts/fit_rl/.fits/ ./rl_fits

Input: get_fit_predictions.py, fit_predictions_task_list.sh
Script: run_fit_predictions.batch
Output: $SERVER_SCRIPTS/fit_rl/.preds/Preds_*_{sub_num}.csv

Input:
Script: concat_rl_output.py -r preds
Output: $SERVER_SCRIPTS/fit_rl/.preds/Preds_*_All.csv

rsync -avzh --include='*_All.csv' --include='*/' --exclude='*' zenkavi@dtn.sherlock.stanford.edu:/oak/stanford/groups/russpold/users/zenkavi/DevStudy_ServerScripts/fit_rl/.preds/ ./rl_preds

==============================bidsify==============================

Copy dataset on Sherlock to have write permissions for the remaining steps
Input: /oak/stanford/groups/russpold/data/ds000054/0.0.1/
Script: copy_dataset.batch
Output: /oak/stanford/groups/russpold/data/ds000054/0.0.2/

Input: fix_nifti_header_tr.py
Script: fix_nifti_header_tr.batch

Raw and preprocessed data of subjects that are moved to sourcedata
Script: mv_exclusions.batch

Fix fieldmap json files
Input: $DATA_LOC/sub-*/fmap/*.json
Script: fix_fmap_jsons.py
Output: $DATA_LOC/sub-*/fmap/*.json

Check BIDS compatibility of dataset
Input: /share/PI/russpold/singularity_images/poldracklab_fmriprep_1.2.5-2018-12-04-2ef6b23ede2a.img
Scripts: run_bids_validator.sh
Output: /bidsify/validator_out.txt

===============================mriqc===============================

Input: NA
Script: make_commands_for_mriqc.py > mriqc_task_list.sh
Output: mriqc_task_list

Input: $DATA_LOC (bidsified), mriqc_task_list.sh, mriqc container
Script: run_mriqc_participant.batch
Output: $DATA_LOC/derivatives/mriqc

Input: $DATA_LOC (bidsified), $DATA_LOC/derivatives/mriqc
Script: run_mriqc_group.batch
Output: $DATA_LOC/derivatives/mriqc/bold.csv, $DATA_LOC/derivatives/mriqc/T1w.csv

=============================fmriprep==============================

Input: NA
Script: make_commands_for_fmriprep.py > fmriprep_task_list.sh
Output: fmriprep_task_list.sh

Input: $DATA_LOC (bidsified), fmriprep_task_list.sh, fmriprep container
Script: run_fmriprep.batch
Output: $DATA_LOC/derivatives/fmriprep

Check output:
Go through fmriprep reports to make sure nobody has errors
Check:
find . -name '*MNI152NLin2009cAsym_desc-preproc_bold.nii.gz' | wc
should be 444 without any missing runs for 74 subjects BUT

find . -path ./sourcedata -prune -o -path ./derivatives -prune -o -name 'sub-*_task-machinegame_run-*_bold.nii.gz' | wc
returns 434 + 5 = 439 because

100103 missing run 6 - converted manually on TACC; needs transfer to Sherlock
100110 missing run 6 - converted manually on TACC; needs transfer to Sherlock
100188 missing run 6 - converted manually on TACC; needs transfer to Sherlock
100241 missing run 6 - converted manually on TACC; needs transfer to Sherlock
306065 missing run 6 - converted manually on TACC; needs transfer to Sherlock

100169 missing runs 4,5,6 (no DICOMs, noted in Subject_fMRI_analysis_tracking)
200025 missing run 6 (no sbref's) - first volume corrupt
408511 missing run 6 - <216 volumes and last volume corrupt

=============================level_1==============================

Input: ave_pes.csv, level_1_utils.py, level1_task_list.sh, level_1.py
Script: run_level1.batch
Output: $DATA_LOC/derivatives/nistats/level_1/sub-*/

Should be 389:
find /oak/stanford/groups/russpold/data/ds000054/0.0.4/derivatives/nistats/level_1 -name 'sub-*_run-*_l1_glm.pkl' | wc
If not run:
Rscript --vanilla debug_l1.R

=============================level_2==============================

Input: level2_task_list.sh, level_2.py
Script: run_level2.batch
Output: $DATA_LOC/derivatives/nistats/level_2/sub-*/

Should be 15*74 = 1110 - 5 = 1105 (due to no junk trials for sub-100062, sub-402997, sub-408952, sub-409381, sub-409850)
find /oak/stanford/groups/russpold/data/ds000054/0.0.4/derivatives/nistats/level_2 -name 'sub-*.nii.gz' | wc

=============================level_3==============================

Input: level2_model*_task_list.sh, level_3.py, $DATA_LOC/derivatives/nistats/level_2/sub-*/contrasts/*
Script: run_level3_model*.batch
Output: $DATA_LOC/derivatives/nistats/level_3/model*/{REG}

Input: $DATA_LOC/derivatives/nistats/level_3/{REG}/all_l2_images*, $DATA_LOC/derivatives/fmriprep_1.3.0/fmriprep/sub-*/func/*brain_mask
Script: make_group_mask.py
Output: $DATA_LOC/derivatives/nistats/level_3/model*/{REG}/group_mask_{MODELNUM}_{REG}.nii.gz

run_rand_model*.batch

Significance checking of randomise output:
echo fslstats model1/lpe/rand_baseline/group_diff_tfce_corrp_tstat1.nii.gz -l 0.95 -V
fslstats /oak/stanford/groups/russpold/data/ds000054/0.0.4/derivatives/nistats/level_3/model1/lpe/rand_baseline/group_diff_tfce_corrp_tstat1.nii.gz -l 0.95 -V
